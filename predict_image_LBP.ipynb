{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597403850905",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import mtcnn\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import face_recognition\n",
    "from scipy import spatial\n",
    "from skimage import feature\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug = True\n",
    "if aug:\n",
    "    path = 'datasets/MTCNN/augmented'\n",
    "    file_encodings = 'encodings_aug_lbp.npy'\n",
    "    predict_save_name = 'predicted_compare_aug_lbp.jpg'\n",
    "    file_names = 'names_lbp.npy'\n",
    "else:\n",
    "    path = 'datasets/single'\n",
    "    file_encodings = 'encodings.npy'\n",
    "    predict_save_name = 'predicted_compare.jpg'\n",
    "    file_names = 'names.npy'\n",
    "\n",
    "threshold = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "\n",
    "    def describe(self, image, eps=1e-7):\n",
    "        lbp = feature.local_binary_pattern(\n",
    "            image, self.numPoints, self.radius, method=\"uniform\").astype(\"uint8\")\n",
    "\n",
    "        hist = cv2.calcHist([lbp], [0], None, [\n",
    "                            self.numPoints+2], [0, self.numPoints+2]).flatten()\n",
    "        #hist = np.histogram(lbp.ravel(), bins=range(0,self.numPoints+3), range=(0,self.numPoints+2))[0]\n",
    "\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum()+eps)\n",
    "\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = LocalBinaryPatterns(24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TIME(f):\n",
    "    def wrapper(*args):\n",
    "        start_time = time.time()\n",
    "        res = f(*args)\n",
    "        end_time = time.time()\n",
    "        print('Run-time: %fs\\n' % (end_time-start_time))\n",
    "        return res\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@TIME\n",
    "def findEncodings():\n",
    "    encodings, names = [], []\n",
    "    for person in os.listdir(path):\n",
    "        if person != '.DS_Store':\n",
    "            image_dir = path + '/' + person\n",
    "            pix = os.listdir(image_dir)\n",
    "            if not os.path.isdir(image_dir):\n",
    "                os.mkdir(image_dir)\n",
    "            # Loop through each training image for the current person\n",
    "            for person_img in pix:\n",
    "                if person_img != '.DS_Store':\n",
    "                    # Get the face encodings for the face in each image file\n",
    "                    img = cv2.imread(image_dir + \"/\" + person_img)\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    # gray = np.array(gray, dtype=\"float\") / 255.0\n",
    "                    feature = desc.describe(gray)\n",
    "                    # face = face_recognition.load_image_file(\n",
    "                    #     image_dir + \"/\" + person_img)\n",
    "\n",
    "                    # face_enc = face_recognition.face_encodings(face)[0]\n",
    "                    # Add face encoding for current image with corresponding label (name) to the training data\n",
    "                    encodings.append(feature)\n",
    "                    names.append(person)\n",
    "    print('\\nNumber of classes: %d\\n' % len(names))\n",
    "    with open(file_encodings, 'wb') as f:\n",
    "        np.save(f, encodings)\n",
    "    with open(file_names, 'wb') as f:\n",
    "        np.save(f, names)\n",
    "    print('Encodings Complete')\n",
    "    return np.array(encodings), np.array(names)\n",
    "\n",
    "\n",
    "@TIME\n",
    "def importFaceEncoded(filename):\n",
    "    # with open(filename, 'rb') as f:\n",
    "    encodeListKnown = np.load(filename)\n",
    "    print(filename + ' has imported!')\n",
    "    return encodeListKnown\n",
    "\n",
    "\n",
    "def face_distance(face_encodings, face_to_compare):\n",
    "    if len(face_encodings) == 0:\n",
    "        return np.empty((0))\n",
    "    # normed = np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
    "    # return normed.T * normed\n",
    "    #----\n",
    "    arr = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        d = 0.5*np.sum(((face_encoding-face_to_compare)**2)/(face_encoding+face_to_compare+1e-10))\n",
    "        arr.append(d)\n",
    "        # arr.append(spatial.distance.cosine(face_encoding, face_to_compare))\n",
    "\n",
    "    return np.array(arr)\n",
    "\n",
    "\n",
    "@TIME\n",
    "def predict():\n",
    "    filename = 'validation/four.jpg'\n",
    "    img = cv2.imread(filename)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detect_faces(img)\n",
    "    face_images = crop_face(filename, img, faces)\n",
    "    labels, confs = [], []\n",
    "    for face in face_images:\n",
    "        feature = desc.describe(face)\n",
    "        d = face_distance(encodings, feature)\n",
    "        matchIndex = np.argmin(d)\n",
    "        labels.append(names[matchIndex])\n",
    "        print(1-d[matchIndex])\n",
    "        confs.append(1-d[matchIndex])\n",
    "    print(labels, confs)\n",
    "    draw_facebox(img, faces, labels, confs, save_img=True)\n",
    "    # img = draw_box(img, face_encodings, face_locations)\n",
    "    # plt.imsave(predict_save_name, img)\n",
    "    # print('Predcited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nNumber of classes: 2842\n\nEncodings Complete\nRun-time: 7.842286s\n\n"
    }
   ],
   "source": [
    "replace = False\n",
    "if not os.path.isfile(file_encodings) or replace:\n",
    "    encodings, names = findEncodings()\n",
    "else:\n",
    "    encodings = importFaceEncoded(file_encodings)\n",
    "    names = importFaceEncoded(file_names)\n",
    "    # mapping = importFaceEncoded(dict_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[91mNumber of face decected: 5\u001b[00m\nDone: 0.999824 validation/four_0.jpg\nDone: 0.999505 validation/four_1.jpg\nDone: 0.998978 validation/four_2.jpg\nDone: 0.995868 validation/four_3.jpg\n\u001b[91mConfidence is lower than Threshold (0.96) | 0.886772 validation/four_4.jpg\u001b[00m\n0.9980938376004888\n0.999634903462333\n0.9992204521606343\n0.9965713642919647\n['B1605247', 'B1509922', 'B1709632', 'B1709632'] [0.9980938376004888, 0.999634903462333, 0.9992204521606343, 0.9965713642919647]\nRun-time: 0.770267s\n\n"
    }
   ],
   "source": [
    "predict()"
   ]
  }
 ]
}